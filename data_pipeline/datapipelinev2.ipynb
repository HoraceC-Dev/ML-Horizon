{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.structured import StructuredOutputParser, ResponseSchema\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from database import MongoDB\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_aws import ChatBedrock\n",
    "from pydantic import BaseModel, Field\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "from websearch import brave_search\n",
    "from web_scrapper import web_scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_sonnet():\n",
    "    load_dotenv()\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    AWS_ACCESS_KEY= os.getenv(\"AWS_ACCESS_KEY\")\n",
    "    llm = ChatBedrock(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "        model_kwargs=dict(temperature=0),\n",
    "        region=\"us-west-2\"\n",
    "    )\n",
    "\n",
    "    return llm\n",
    "\n",
    "def llm_llama3b():\n",
    "    return OllamaLLM(model=\"llama3.2:latest\", temperature=0.0, top_k=20, top_p= 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerCreator(TypedDict):\n",
    "    list_of_questions: List[str]\n",
    "    question_answer_pair: dict\n",
    "\n",
    "def question_retriever(state):\n",
    "    load_dotenv()\n",
    "    MONGODB_USER_NAME = os.getenv(\"MONGODB_USER_NAME\")\n",
    "    MONGODB_USER_PASSWORD= os.getenv(\"MONGODB_USER_PASSWORD\")\n",
    "\n",
    "    db = MongoDB(MONGODB_USER_NAME, MONGODB_USER_PASSWORD)\n",
    "\n",
    "    question_list = db.get_question()\n",
    "    db.close_connection()\n",
    "    return {\"list_of_questions\": question_list}\n",
    "\n",
    "def web_content_summarization(input_dict):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "Role: Formatting Expert\n",
    "             \n",
    "Task: You will be given a long text formatted in an unqiue way. Your primary task is to reformat the text into detail, precise, and legible format.\n",
    "The length of the output can be anywhere from 3 parahgraphs to 10 paragraphs depending on the context. Keep in mind that the technical explaination of some concepts are keys,\n",
    "make sure to include all the technical aspect of the orginal content.\n",
    "\"\"\"),\n",
    "(\"human\", \"Please reformat the document in detailed paragraphs so it is more legible.\\n Title: {title}\\n\\n URL Available:{url}\\n\\n Content:{input_text}\")\n",
    "        ]\n",
    "    )\n",
    "    format_text_chain = prompt | llm_llama3b()\n",
    "    formatted_text = format_text_chain.invoke({\"input_text\": input_dict[\"description\"], \"title\": input_dict[\"title\"], \"url\": input_dict[\"url\"]})\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "def question_from_content(llm_input):\n",
    "    class Schema(BaseModel):\n",
    "        org_question_answer: str = Field(description= \"This variable stores the response to the original question using the information from the given text.\")\n",
    "        additional_quiestion_answer_pairs: dict[str,str] = Field(description=\"This variable stores the additional questions answer pairs where the question will be the key and the corresponding answer will be the value in the dictionary. Depending on the information given, formulate 2-8 question-answer pairs\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "Role: Question Explorer\n",
    "             \n",
    "Task: You will be given a text and a question. Not only you need to formulate an answer for that question but to discover\n",
    "potential questions that can also be answered from the same text. For example, you have an original question: What is Machine Learning? \n",
    "Formulate a response using the information from the text, but also identify any potential questions like: Is Machine Learning a subset of AI? that can also \n",
    "be answered from the given text. \n",
    "\"\"\"),\n",
    "(\"human\", \"This is the information I have for you: {text}\"),\n",
    "(\"human\", \"Use the provided information above to answer this question: {question}. Also try to identify potential questions that the given text has the answer to then formulate a response for those questions as well.\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_sonnet().with_structured_output(Schema)\n",
    "\n",
    "    result = chain.invoke({\"text\":llm_input[\"web_content\"],\"question\": llm_input[\"question\"]})\n",
    "\n",
    "    return result.org_question_answer, result.additional_quiestion_answer_pairs\n",
    "\n",
    "def create_content(state):\n",
    "    list_of_questions = state[\"list_of_questions\"][0]\n",
    "    temp_dict = {}\n",
    "    for question_doc in list_of_questions:\n",
    "        question = question_doc[\"text\"]\n",
    "        list_of_webs = brave_search(question, num_results=3,freshness=\"2020-10-09to2024-10-30\")\n",
    "        web_content = \"\"\n",
    "        list_of_url = []\n",
    "        for web, index in enumerate(list_of_webs):\n",
    "            result = web_scrapper(web[\"URL\"])\n",
    "            list_of_url.append(result['url']) \n",
    "            web_content = web_content + f\"Source No.{index+1}\"\n",
    "            web_content = web_content + web_content_summarization(result)\n",
    "        \n",
    "        \n",
    "\n",
    "        ans_to_org_question, question_answer_pairs = question_from_content({\"web_content\": web_content, \"question\": question})\n",
    "        question_answer_pairs[f\"question\"] = ans_to_org_question\n",
    "        temp_dict = {**temp_dict, **question_answer_pairs}\n",
    "\n",
    "    print(temp_dict)\n",
    "    return {\"question_answer_pairs\": temp_dict}\n",
    "\n",
    "def store_web_info(web_dict):\n",
    "    load_dotenv()\n",
    "    MONGODB_USER_NAME = os.getenv(\"MONGODB_USER_NAME\")\n",
    "    MONGODB_USER_PASSWORD= os.getenv(\"MONGODB_USER_PASSWORD\")\n",
    "    uri = f\"mongodb+rv://{MONGODB_USER_NAME}:{MONGODB_USER_PASSWORD}@mldatabase.36zie.mongodb.net/?retryWrites=true&w=majority&appName=MLDatabase\"\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    db = client[\"MLHorizon\"]\n",
    "    collection = db.MLWebInfo\n",
    "    collection.insertOne(web_dict)\n",
    "    client.close()\n",
    "\n",
    "def database_organization(state):\n",
    "    \n",
    "    load_dotenv()\n",
    "    MONGODB_USER_NAME = os.getenv(\"MONGODB_USER_NAME\")\n",
    "    MONGODB_USER_PASSWORD= os.getenv(\"MONGODB_USER_PASSWORD\")\n",
    "    uri = f\"mongodb+rv://{MONGODB_USER_NAME}:{MONGODB_USER_PASSWORD}@mldatabase.36zie.mongodb.net/?retryWrites=true&w=majority&appName=MLDatabase\"\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    db = client[\"MLHorizon\"]\n",
    "    collection = d\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_learner_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     list_of_questions: List[\u001b[38;5;28mstr\u001b[39m]\n\u001b[0;32m      6\u001b[0m question_data_extractor_graph \u001b[38;5;241m=\u001b[39m StateGraph(QuestionPipeline)\n\u001b[1;32m----> 7\u001b[0m question_data_extractor_graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mml_learner_chain\u001b[49m)\n\u001b[0;32m      8\u001b[0m question_data_extractor_graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_expander\u001b[39m\u001b[38;5;124m\"\u001b[39m,question_extractor_chain)\n\u001b[0;32m      9\u001b[0m question_data_extractor_graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase_synchronization\u001b[39m\u001b[38;5;124m\"\u001b[39m, synchronization)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ml_learner_chain' is not defined"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"list_of_questions\": [],\n",
    "\"question_answer_pairs\"{}\n",
    "new_question_answer_p\n",
    "\n",
    "\n",
    "airs = {}\n",
    "\n",
    "\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
